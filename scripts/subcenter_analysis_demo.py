#!/usr/bin/env python
"""
å­ä¸­å¿ƒè¯†åˆ«å’Œç”Ÿå‘½å‘¨æœŸè¿½è¸ªæ¼”ç¤ºè„šæœ¬
ä¸“é—¨ç”¨äºŽæ¼”ç¤ºRQ1ç›¸å…³çš„å­ä¸­å¿ƒåˆ†æžåŠŸèƒ½
"""

import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

import pandas as pd
import numpy as np
import networkx as nx
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

from src.utils.logging_config import setup_logger
from src.network_analysis.community_detection import (
    CommunityDetector, 
    SubCenterDetector, 
    SubCenterLifecycleTracker,
    analyze_subcenters_and_lifecycle
)

# è®¾ç½®æ—¥å¿—
logger = setup_logger(__name__)


def create_sample_network_for_demo():
    """åˆ›å»ºç¤ºä¾‹ç½‘ç»œç”¨äºŽæ¼”ç¤ºå­ä¸­å¿ƒè¯†åˆ«åŠŸèƒ½"""
    print("ðŸ”§ åˆ›å»ºç¤ºä¾‹å¼‚æž„ç½‘ç»œ...")
    
    from config.settings import NETWORK_OUTPUT_DIR, FILENAMES
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    NETWORK_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    
    # åˆ›å»ºå¼‚æž„å›¾
    G = nx.Graph()
    
    # === æ·»åŠ èŠ‚ç‚¹ ===
    
    # 1. æ ¸å¿ƒå›¢é˜Ÿæˆå‘˜ï¼ˆå®˜æ–¹ï¼‰
    core_team = [
        ("user_0", {"type": "user", "login": "hwchase17", "user_type": "core"}),
        ("user_1", {"type": "user", "login": "agola11", "user_type": "core"}),
        ("user_2", {"type": "user", "login": "baskaryan", "user_type": "core"}),
        ("user_3", {"type": "user", "login": "ccurme", "user_type": "core"}),
    ]
    
    # 2. ç¤¾åŒºç”¨æˆ·ï¼ˆæ½œåœ¨å­ä¸­å¿ƒæˆå‘˜ï¼‰
    community_users = []
    for i in range(4, 50):
        community_users.append((
            f"user_{i}", 
            {"type": "user", "login": f"community_user_{i}", "user_type": "community"}
        ))
    
    # 3. ä»“åº“èŠ‚ç‚¹
    repos = []
    repo_types = ['application', 'library', 'tool', 'tutorial']
    for i in range(100):
        repo_type = np.random.choice(repo_types)
        repos.append((
            f"repo_{i}",
            {
                "type": "repo", 
                "name": f"repo_{i}", 
                "primary_role": repo_type,
                "stars": np.random.randint(5, 1000),
                "forks": np.random.randint(1, 100)
            }
        ))
    
    # 4. PRèŠ‚ç‚¹
    prs = []
    contribution_types = ['code', 'doc']
    for i in range(200):
        contrib_type = np.random.choice(contribution_types, p=[0.7, 0.3])
        prs.append((
            f"pr_{i}",
            {
                "type": "pr",
                "contribution_type": contrib_type,
                "timestamp": f"2023-{np.random.randint(1,13):02d}-{np.random.randint(1,29):02d}T10:00:00Z"
            }
        ))
    
    # 5. IssueèŠ‚ç‚¹
    issues = []
    for i in range(150):
        issues.append((
            f"issue_{i}",
            {
                "type": "issue",
                "timestamp": f"2023-{np.random.randint(1,13):02d}-{np.random.randint(1,29):02d}T10:00:00Z"
            }
        ))
    
    # æ·»åŠ æ‰€æœ‰èŠ‚ç‚¹
    G.add_nodes_from(core_team + community_users + repos + prs + issues)
    
    # === æ·»åŠ è¾¹ï¼ˆæ¨¡æ‹Ÿä¸åŒçš„äº¤äº’æ¨¡å¼ï¼‰ ===
    
    # 1. æ ¸å¿ƒå›¢é˜Ÿä¸Žä¸»è¦ä»“åº“çš„è¿žæŽ¥
    for core_user, _ in core_team:
        for i in range(0, 20):  # è¿žæŽ¥å‰20ä¸ªä»“åº“
            G.add_edge(core_user, f"repo_{i}", type="maintain")
    
    # 2. åˆ›å»ºå‡ ä¸ªåŠŸèƒ½æ€§å­ä¸­å¿ƒ
    
    # å­ä¸­å¿ƒ1ï¼šåº”ç”¨å¼€å‘è€…ç¾¤ä½“ (users 4-15)
    app_developers = [f"user_{i}" for i in range(4, 16)]
    app_repos = [f"repo_{i}" for i in range(20, 40) if repos[i-20][1]["primary_role"] == "application"]
    
    for user in app_developers:
        # è¿žæŽ¥åˆ°åº”ç”¨ä»“åº“
        for repo in app_repos[:5]:  # æ¯äººè¿žæŽ¥5ä¸ªåº”ç”¨ä»“åº“
            G.add_edge(user, repo, type="contribute")
        
        # åˆ›å»ºä»£ç PR
        for i in range(3):
            pr_id = f"pr_{len(app_developers)*3 + i}"
            if pr_id in [node for node, _ in prs]:
                G.add_edge(user, pr_id, type="create", contribution_type="code")
    
    # å­ä¸­å¿ƒ2ï¼šæ–‡æ¡£è´¡çŒ®è€…ç¾¤ä½“ (users 16-25)
    doc_contributors = [f"user_{i}" for i in range(16, 26)]
    
    for user in doc_contributors:
        # è¿žæŽ¥åˆ°å„ç§ä»“åº“ï¼ˆæ–‡æ¡£è´¡çŒ®è€…æ›´å¤šæ ·åŒ–ï¼‰
        for i in range(5):
            repo_id = f"repo_{np.random.randint(0, 50)}"
            G.add_edge(user, repo_id, type="document")
        
        # åˆ›å»ºæ–‡æ¡£PR
        for i in range(2):
            pr_id = f"pr_{50 + len(doc_contributors)*2 + i}"
            if pr_id in [node for node, _ in prs]:
                G.add_edge(user, pr_id, type="create", contribution_type="doc")
    
    # å­ä¸­å¿ƒ3ï¼šå·¥å…·å¼€å‘è€…ç¾¤ä½“ (users 26-35)
    tool_developers = [f"user_{i}" for i in range(26, 36)]
    tool_repos = [f"repo_{i}" for i in range(60, 80) if repos[i-60][1]["primary_role"] == "tool"]
    
    for user in tool_developers:
        # è¿žæŽ¥åˆ°å·¥å…·ä»“åº“
        for repo in tool_repos[:3]:
            G.add_edge(user, repo, type="develop")
        
        # åˆ›å»ºä»£ç PR
        for i in range(4):  # å·¥å…·å¼€å‘è€…æ›´æ´»è·ƒ
            pr_id = f"pr_{100 + len(tool_developers)*4 + i}"
            if pr_id in [node for node, _ in prs]:
                G.add_edge(user, pr_id, type="create", contribution_type="code")
    
    # 3. æ·»åŠ Issueäº¤äº’
    all_users = [f"user_{i}" for i in range(50)]
    for i, (issue_id, _) in enumerate(issues):
        # éšæœºé€‰æ‹©ç”¨æˆ·ä¸ŽIssueäº¤äº’
        interacting_users = np.random.choice(all_users, size=np.random.randint(1, 4), replace=False)
        for user in interacting_users:
            G.add_edge(user, issue_id, type="interact")
    
    # 4. æ·»åŠ æ—¶é—´æˆ³åˆ°è¾¹
    for u, v, data in G.edges(data=True):
        if 'timestamp' not in data:
            # ä¸ºè¾¹æ·»åŠ éšæœºæ—¶é—´æˆ³
            month = np.random.randint(1, 13)
            day = np.random.randint(1, 29)
            data['timestamp'] = f"2023-{month:02d}-{day:02d}T{np.random.randint(9,18):02d}:00:00Z"
    
    # ä¿å­˜ç½‘ç»œå›¾
    graph_path = NETWORK_OUTPUT_DIR / FILENAMES["graph_file"]
    nx.write_graphml(G, str(graph_path))
    
    print(f"âœ… ç¤ºä¾‹ç½‘ç»œåˆ›å»ºå®Œæˆ:")
    print(f"   - èŠ‚ç‚¹æ•°: {G.number_of_nodes()}")
    print(f"   - è¾¹æ•°: {G.number_of_edges()}")
    print(f"   - ç”¨æˆ·èŠ‚ç‚¹: {len([n for n, d in G.nodes(data=True) if d.get('type') == 'user'])}")
    print(f"   - ä»“åº“èŠ‚ç‚¹: {len([n for n, d in G.nodes(data=True) if d.get('type') == 'repo'])}")
    print(f"   - PRèŠ‚ç‚¹: {len([n for n, d in G.nodes(data=True) if d.get('type') == 'pr'])}")
    print(f"   - IssueèŠ‚ç‚¹: {len([n for n, d in G.nodes(data=True) if d.get('type') == 'issue'])}")
    print(f"   - ç½‘ç»œå›¾å·²ä¿å­˜è‡³: {graph_path}")
    
    return True


def run_subcenter_identification_demo():
    """è¿è¡Œå­ä¸­å¿ƒè¯†åˆ«æ¼”ç¤º"""
    print("\nðŸŽ¯ è¿è¡Œå­ä¸­å¿ƒè¯†åˆ«æ¼”ç¤º...")
    
    try:
        from config.settings import NETWORK_OUTPUT_DIR, FILENAMES, ANALYSIS_CONFIG
        
        # åŠ è½½ç½‘ç»œå›¾
        graph_path = NETWORK_OUTPUT_DIR / FILENAMES["graph_file"]
        G = nx.read_graphml(str(graph_path))
        
        print(f"   - å·²åŠ è½½ç½‘ç»œå›¾: {G.number_of_nodes()} ä¸ªèŠ‚ç‚¹, {G.number_of_edges()} æ¡è¾¹")
        
        # ç¤¾åŒºæ£€æµ‹
        print("   - æ‰§è¡Œç¤¾åŒºæ£€æµ‹...")
        detector = CommunityDetector(G)
        communities = detector.detect_louvain_communities()
        print(f"   - æ£€æµ‹åˆ° {len(communities)} ä¸ªç¤¾åŒº")
        
        # å­ä¸­å¿ƒè¯†åˆ«
        print("   - è¯†åˆ«å­ä¸­å¿ƒ...")
        subcenter_detector = SubCenterDetector(
            G, 
            core_team_logins=ANALYSIS_CONFIG["core_team_logins"],
            min_subcenter_size=5,  # é™ä½Žé˜ˆå€¼ä»¥ä¾¿æ¼”ç¤º
            innovation_threshold=0.01  # é™ä½Žé˜ˆå€¼ä»¥ä¾¿æ¼”ç¤º
        )
        
        subcenters = subcenter_detector.identify_sub_centers(communities, 'louvain')
        
        if subcenters:
            print(f"   âœ… æˆåŠŸè¯†åˆ«å‡º {len(subcenters)} ä¸ªå­ä¸­å¿ƒ")
            
            # æ˜¾ç¤ºå­ä¸­å¿ƒè¯¦ç»†ä¿¡æ¯
            for i, sc in enumerate(subcenters):
                print(f"\n   å­ä¸­å¿ƒ {i+1}:")
                print(f"     - ID: {sc['subcenter_id']}")
                print(f"     - è§„æ¨¡: {sc['size']} ä¸ªèŠ‚ç‚¹")
                print(f"     - åŠŸèƒ½ç±»åž‹: {sc['functional_type']}")
                print(f"     - åˆ›æ–°å¾—åˆ†: {sc['innovation_score']:.3f}")
                print(f"     - åº”ç”¨åˆ›å»ºçŽ‡: {sc['app_creation_rate']:.3f}")
                print(f"     - ä»£ç è´¡çŒ®çŽ‡: {sc['code_contribution_rate']:.3f}")
                print(f"     - çŸ¥è¯†åˆ†äº«çŽ‡: {sc['knowledge_sharing_rate']:.3f}")
                print(f"     - ä¸“ä¸šåŒ–æŒ‡æ•°: {sc['specialization_index']:.3f}")
                print(f"     - å¤–éƒ¨è¿žæŽ¥åº¦: {sc['external_connectivity']:.3f}")
                print(f"     - å†…éƒ¨å¯†åº¦: {sc['internal_density']:.3f}")
                print(f"     - å…³é”®èŠ‚ç‚¹æ•°: {len(sc['key_nodes'])}")
            
            return True
        else:
            print("   âš ï¸  æœªè¯†åˆ«å‡ºç¬¦åˆæ¡ä»¶çš„å­ä¸­å¿ƒ")
            return False
            
    except Exception as e:
        print(f"   âŒ å­ä¸­å¿ƒè¯†åˆ«æ¼”ç¤ºå¤±è´¥: {e}")
        return False


def run_lifecycle_tracking_demo():
    """è¿è¡Œç”Ÿå‘½å‘¨æœŸè¿½è¸ªæ¼”ç¤º"""
    print("\nðŸ“ˆ è¿è¡Œç”Ÿå‘½å‘¨æœŸè¿½è¸ªæ¼”ç¤º...")
    
    try:
        from config.settings import NETWORK_OUTPUT_DIR, FILENAMES
        
        # åŠ è½½ç½‘ç»œå›¾
        graph_path = NETWORK_OUTPUT_DIR / FILENAMES["graph_file"]
        G = nx.read_graphml(str(graph_path))
        
        print("   - åˆ›å»ºç”Ÿå‘½å‘¨æœŸè¿½è¸ªå™¨...")
        
        # åˆ›å»ºç”Ÿå‘½å‘¨æœŸè¿½è¸ªå™¨ï¼ˆç¼©çŸ­æ—¶é—´èŒƒå›´ç”¨äºŽæ¼”ç¤ºï¼‰
        lifecycle_tracker = SubCenterLifecycleTracker(
            start_date="2023-01-01",
            end_date="2023-06-30",  # 6ä¸ªæœˆçš„æ¼”ç¤ºæ•°æ®
            similarity_threshold=0.2,  # é™ä½Žé˜ˆå€¼ä»¥ä¾¿æ¼”ç¤º
            stability_threshold=2  # é™ä½Žç¨³å®šæ€§é˜ˆå€¼
        )
        
        print("   - è¿½è¸ªå­ä¸­å¿ƒç”Ÿå‘½å‘¨æœŸæ¼”åŒ–...")
        lifecycle_df = lifecycle_tracker.track_subcenter_evolution(G, algorithm='louvain')
        
        if not lifecycle_df.empty:
            print(f"   âœ… æˆåŠŸè¿½è¸ªåˆ° {len(lifecycle_df)} ä¸ªå­ä¸­å¿ƒå®¶æ—è°±ç³»")
            
            # ç”Ÿæˆæ‘˜è¦ç»Ÿè®¡
            summary = lifecycle_tracker.generate_lifecycle_summary(lifecycle_df)
            
            print(f"\n   ç”Ÿå‘½å‘¨æœŸè¿½è¸ªæ‘˜è¦:")
            print(f"     - æ€»å®¶æ—æ•°: {summary['total_subcenters']}")
            print(f"     - å½“å‰æ´»è·ƒ: {summary['active_subcenters']}")
            print(f"     - å·²æ¶ˆå¤±: {summary['extinct_subcenters']}")
            print(f"     - ç¨³å®šå­ä¸­å¿ƒ: {summary['stable_subcenters']}")
            print(f"     - å¹³å‡å¯¿å‘½: {summary['avg_lifespan']:.1f} ä¸ªæœˆ")
            print(f"     - æœ€é•¿å¯¿å‘½: {summary['max_lifespan']} ä¸ªæœˆ")
            print(f"     - å¹³å‡å³°å€¼è§„æ¨¡: {summary['avg_peak_size']:.1f}")
            
            print(f"\n   ç”Ÿå‘½å‘¨æœŸç±»åž‹åˆ†å¸ƒ:")
            for lc_type, count in summary['lifecycle_type_distribution'].items():
                print(f"     - {lc_type}: {count}")
            
            print(f"\n   åŠŸèƒ½ç±»åž‹åˆ†å¸ƒ:")
            for func_type, count in summary['functional_type_distribution'].items():
                print(f"     - {func_type}: {count}")
            
            # æ˜¾ç¤ºå‡ ä¸ªå…¸åž‹çš„ç”Ÿå‘½å‘¨æœŸæ¡ˆä¾‹
            print(f"\n   å…¸åž‹ç”Ÿå‘½å‘¨æœŸæ¡ˆä¾‹:")
            for i, row in lifecycle_df.head(3).iterrows():
                print(f"     æ¡ˆä¾‹ {i+1}:")
                print(f"       - å®¶æ—ID: {row['lineage_id']}")
                print(f"       - ç”Ÿå‘½å‘¨æœŸç±»åž‹: {row['lifecycle_type']}")
                print(f"       - è¯žç”Ÿæœˆä»½: {row['birth_month']}")
                print(f"       - æ­»äº¡æœˆä»½: {row['death_month'] if row['death_month'] else 'ä»æ´»è·ƒ'}")
                print(f"       - æ€»å¯¿å‘½: {row['total_lifespan_months']} ä¸ªæœˆ")
                print(f"       - å³°å€¼è§„æ¨¡: {row['peak_size']}")
                print(f"       - ä¸»å¯¼åŠŸèƒ½: {row['dominant_functional_type']}")
                print(f"       - æœ€ç»ˆçŠ¶æ€: {row['final_status']}")
            
            # å¯è§†åŒ–ç”Ÿå‘½å‘¨æœŸæ¨¡å¼
            print("   - ç”Ÿæˆç”Ÿå‘½å‘¨æœŸå¯è§†åŒ–...")
            lifecycle_tracker.visualize_lifecycle_patterns(lifecycle_df)
            
            return True
        else:
            print("   âš ï¸  æœªèƒ½è¿½è¸ªåˆ°ç”Ÿå‘½å‘¨æœŸæ•°æ®")
            return False
            
    except Exception as e:
        print(f"   âŒ ç”Ÿå‘½å‘¨æœŸè¿½è¸ªæ¼”ç¤ºå¤±è´¥: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("ðŸš€ å­ä¸­å¿ƒè¯†åˆ«å’Œç”Ÿå‘½å‘¨æœŸè¿½è¸ª - åŠŸèƒ½æ¼”ç¤º")
    print("=" * 60)
    print("è¿™ä¸ªæ¼”ç¤ºè„šæœ¬å°†å±•ç¤ºå¦‚ä½•è¯†åˆ«ç½‘ç»œä¸­çš„åˆ›æ–°å­ä¸­å¿ƒ")
    print("ä»¥åŠè¿½è¸ªå®ƒä»¬çš„ç”Ÿå‘½å‘¨æœŸæ¼”åŒ–è¿‡ç¨‹")
    print("=" * 60)
    
    start_time = datetime.now()
    
    # æ‰§è¡Œæ¼”ç¤ºæ­¥éª¤
    steps = [
        ("åˆ›å»ºç¤ºä¾‹ç½‘ç»œ", create_sample_network_for_demo),
        ("å­ä¸­å¿ƒè¯†åˆ«æ¼”ç¤º", run_subcenter_identification_demo),
        ("ç”Ÿå‘½å‘¨æœŸè¿½è¸ªæ¼”ç¤º", run_lifecycle_tracking_demo)
    ]
    
    results = []
    
    for step_name, step_func in steps:
        print(f"\n{'='*20} {step_name} {'='*20}")
        try:
            result = step_func()
            results.append((step_name, result))
            
            if result:
                print(f"âœ… {step_name} - æˆåŠŸ")
            else:
                print(f"âš ï¸  {step_name} - éƒ¨åˆ†æˆåŠŸ")
                
        except Exception as e:
            print(f"âŒ {step_name} - å¤±è´¥: {e}")
            results.append((step_name, False))
    
    # æ±‡æ€»ç»“æžœ
    end_time = datetime.now()
    duration = end_time - start_time
    
    print("\n" + "=" * 60)
    print("ðŸ“‹ æ¼”ç¤ºç»“æžœæ±‡æ€»")
    print("=" * 60)
    
    success_count = 0
    for step_name, success in results:
        status = "âœ… æˆåŠŸ" if success else "âŒ å¤±è´¥"
        print(f"   {step_name}: {status}")
        if success:
            success_count += 1
    
    success_rate = success_count / len(results) * 100
    
    print(f"\nðŸŽ¯ æˆåŠŸçŽ‡: {success_count}/{len(results)} ({success_rate:.0f}%)")
    print(f"â±ï¸  æ€»è€—æ—¶: {duration}")
    
    if success_rate >= 80:
        print("\nðŸŽ‰ å­ä¸­å¿ƒè¯†åˆ«å’Œç”Ÿå‘½å‘¨æœŸè¿½è¸ªåŠŸèƒ½æ¼”ç¤ºæˆåŠŸï¼")
        print("\nðŸ“š å…³é”®åŠŸèƒ½:")
        print("   âœ“ åŸºäºŽç¤¾åŒºæ£€æµ‹è¯†åˆ«éžå®˜æ–¹åˆ›æ–°å­ä¸­å¿ƒ")
        print("   âœ“ è®¡ç®—å­ä¸­å¿ƒçš„åˆ›æ–°æŒ‡æ ‡å’ŒåŠŸèƒ½ç‰¹å¾")
        print("   âœ“ è¿½è¸ªå­ä¸­å¿ƒçš„æ—¶é—´æ¼”åŒ–å’Œç”Ÿå‘½å‘¨æœŸ")
        print("   âœ“ åˆ†æžå­ä¸­å¿ƒçš„æ¶ŒçŽ°ã€å‘å±•ã€è¡°é€€æ¨¡å¼")
        print("   âœ“ å¯è§†åŒ–ç”Ÿå‘½å‘¨æœŸåˆ†å¸ƒå’Œæ¼”åŒ–è¶‹åŠ¿")
        
        print("\nðŸ”¬ ç ”ç©¶ä»·å€¼:")
        print("   â€¢ æ”¯æŒRQ1: ç½‘ç»œç»“æž„ä»Žä¸­å¿ƒåŒ–å‘å¤šä¸­å¿ƒæ¼”åŒ–çš„å®žè¯åˆ†æž")
        print("   â€¢ è¯†åˆ«ç¤¾åŒºé©±åŠ¨çš„åˆ›æ–°å­ä¸­å¿ƒåŠå…¶åŠŸèƒ½å®šä½")
        print("   â€¢ é‡åŒ–å­ä¸­å¿ƒçš„ç”Ÿå‘½å‘¨æœŸæ¨¡å¼å’Œç¨³å®šæ€§")
        print("   â€¢ ä¸ºç†è§£å¼€æºç”Ÿæ€ç³»ç»Ÿæ²»ç†æ¼”åŒ–æä¾›å¾®è§‚æœºåˆ¶æ´žå¯Ÿ")
        
    else:
        print("\nâš ï¸  éƒ¨åˆ†åŠŸèƒ½å­˜åœ¨é—®é¢˜ï¼Œå»ºè®®æ£€æŸ¥:")
        print("   - ç½‘ç»œå›¾æ•°æ®çš„å®Œæ•´æ€§")
        print("   - ç¤¾åŒºæ£€æµ‹ç®—æ³•çš„å¯ç”¨æ€§")
        print("   - ä¸­å¿ƒæ€§è®¡ç®—çš„ä¾èµ–åŒ…")
    
    print(f"\nðŸ“ è¾“å‡ºæ–‡ä»¶ä½ç½®:")
    print("   - ç¤ºä¾‹ç½‘ç»œ: data/network/network_output/full_ecosystem_graph.graphml")
    print("   - é™æ€å­ä¸­å¿ƒ: results/analysis_output/static_subcenters_analysis.csv")
    print("   - ç”Ÿå‘½å‘¨æœŸæ•°æ®: results/analysis_output/subcenter_lifecycle_louvain.csv")
    print("   - ç”Ÿå‘½å‘¨æœŸæ‘˜è¦: results/analysis_output/subcenter_lifecycle_summary.json")
    print("   - å¯è§†åŒ–å›¾è¡¨: results/analysis_output/subcenter_lifecycle_patterns.png")
    
    return success_rate >= 50


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
